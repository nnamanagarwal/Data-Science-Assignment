{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55815c9-3bff-4cbb-84ae-69235fb5eebd",
   "metadata": {},
   "source": [
    "## Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ebc349-c6e8-43ce-90bf-23fe6166b1e1",
   "metadata": {},
   "source": [
    "* Assumptions for ANOVA\n",
    "\n",
    "1. Normality of sampling distribution of mean: It means the distribution of sample means must follow normal distribution (central limit theory)\n",
    "2. Absence of outliers: It means that outlying scores need to be removed before performing ANOVA\n",
    "3. Homogenity of variance: It means that population variance in different level of the each independent variable or factor is the same. [σ1²=σ2²=σ3²]\n",
    "4. Samples are independent avnd random\n",
    "\n",
    "* Some examples of violations that could impact the validity of the results:\n",
    "\n",
    "__Non-normality:__ If the data within each group is not normally distributed, the ANOVA results may be unreliable. For example, if the data is skewed or has outliers, it may violate the assumption of normality.\n",
    "\n",
    "__Heteroscedasticity:__ If the variances of the data within each group are not equal, the ANOVA results may be unreliable. For example, if the data within one group has much larger variances than another group, it may violate the assumption of homogeneity of variances.\n",
    "\n",
    "__Lack of independence:__ If the observations within each group are not independent of each other, the ANOVA results may be unreliable. For example, if the same group of individuals is measured at multiple time points, the observations may not be independent, violating the assumption of independence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e59de-1ea5-4066-a497-bdf315176a57",
   "metadata": {},
   "source": [
    "## What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d67ffb-3fda-422c-8bd9-96e39e4a0957",
   "metadata": {},
   "source": [
    " Three main types of ANOVA are:\n",
    "\n",
    "1. One Way ANOVA : Used when there is one factor with atleast 2 levels and the levels are independent of each other\n",
    "2. Repeated Measures ANOVA : Used when ther is one factor with atleast 2 levels and the levels are dependent on each other\n",
    "3. Factorial ANOVA : Used when there are 2 or more factors and each factor has 2 or more levels and the levels may be dependent or independent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba8be5-a627-4480-97f5-c900eaf2b85a",
   "metadata": {},
   "source": [
    "## What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da242cc-32c5-481f-9696-14abf373e7dd",
   "metadata": {},
   "source": [
    "Partitioning of variance in ANOVA refers to hypothesis testing and it is as follows:\n",
    "\n",
    "* Null hypothesis (H0) : σ1²=σ2²=σ3²= .......σk² (k = number of levels) \n",
    "\n",
    "* Alternate hypothesis (Ha): Atleas one of the sample mean is not equal\n",
    "\n",
    "* The test statistic in ANOVA is the F test:\n",
    "\n",
    "* F = (Variance between samples) / (Variance within samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85444f0d-4e17-4398-a0ef-908d2e6e907f",
   "metadata": {},
   "source": [
    "## How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ac325a-76bc-42f4-95e1-3d6dc0a961f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({\"Group 1\":[79,78,88,94,92,85,83,85,82,81],\"Group 2\":[85,86,88,75,78,94,98,79,71,80],\"Group 3\":[91,92,93,85,87,84,82,88,95,96]})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d862d277-0fb5-44d6-807d-709c9a85e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group mean:\n",
      "Group 1    84.7\n",
      "Group 2    83.4\n",
      "Group 3    89.3\n",
      "dtype: float64\n",
      "\n",
      "Total mean =  85.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate the group means and the total mean.\n",
    "total_mean = df.unstack().mean()\n",
    "group_mean = df.mean()\n",
    "print('Group mean:')\n",
    "print(group_mean)\n",
    "print('\\nTotal mean = ',total_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1a137b-7cab-4e30-8baf-8d023c23bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Square, SST =  1292.8\n"
     ]
    }
   ],
   "source": [
    "#Calculate the sum of squares total\n",
    "## tss = summation ( sample value - total mean)**2\n",
    "\n",
    "tss = 0\n",
    "for i in df.unstack():\n",
    "    tss += (i - total_mean)**2\n",
    "    \n",
    "print('Total Sum of Square, SST = ',tss.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3822fca-8855-4445-a6e5-303e6b7bfdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Sum of Squares, SSE =  192.2\n"
     ]
    }
   ],
   "source": [
    "# Calculate explained sum of squares \n",
    "## sse = summation ( length of group*( group mean - total mean)**2)\n",
    "\n",
    "n= 10\n",
    "sse = np.sum(n * (group_mean -  total_mean)**2)\n",
    "print('Explained Sum of Squares, SSE = ',sse.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4689266b-adc3-4c7a-9cf3-7c6cb8ca5497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Sum of Squares, SSR 1100.6\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sum of squares residual\n",
    "\n",
    "ssr = tss - sse\n",
    "print('Residual Sum of Squares, SSR',ssr.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9315da9-3c6c-459c-95ec-d07a04efac74",
   "metadata": {},
   "source": [
    "## In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b77ff7-845f-4008-8e91-11d3d369888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effects:\n",
      "                 sum_sq   df           F\n",
      "freq_father  819.597644  1.0  161.644532\n",
      "freq_son     755.906043  1.0  149.083003\n",
      "\n",
      "Interactions:\n",
      "                          sum_sq    df          F\n",
      "freq_father:freq_son  195.381663   1.0  38.534002\n",
      "Residual              136.900000  27.0        NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# here we have a data of consumption of fuel of a car when father drives and son drives with frequencies of a week\n",
    "data = pd.DataFrame({'freq_father': np.repeat([1,2,3], 10), \n",
    "                     'freq_son': np.repeat([2,3,1], 10), \n",
    "                     'consumption': [10, 12, 13, 9, 8, 14, 12, 11, 14, 8, \n",
    "                                    22, 28, 23, 22, 27, 26, 25, 24, 23, 28, \n",
    "                                    15, 21, 16, 17, 20, 21, 20, 19, 18, 17]})\n",
    "\n",
    "# Fit the ANOVA model using the formula interface\n",
    "model = ols('consumption ~ freq_father + freq_son + freq_father: freq_son', data=data).fit()\n",
    "\n",
    "# Calculate the ANOVA table\n",
    "result = sm.stats.anova_lm(model,  typ = 2)\n",
    "\n",
    "# Extract the main effects and interaction effects from the table\n",
    "main = result.iloc[:-2, :-1]\n",
    "interaction = result.iloc[2:, :-1]\n",
    "\n",
    "# Print the main effects and interaction effects\n",
    "print(f'Main Effects:\\n{main}\\n')\n",
    "print(f'Interactions:\\n{interaction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6c84c-49ea-41f9-a16b-cb7923f8e80c",
   "metadata": {},
   "source": [
    "## Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f67d1d-7d3d-40c1-95cc-e0d725a5c529",
   "metadata": {},
   "source": [
    "Since the value of p i.e., 0.02 is less than alpha i.e., 0.05.\n",
    "* we can reject the null hypothesis.\n",
    "* which means we can state that there is a significant difference in the means between the groups.\n",
    "* There is a significant effect of the independent variable on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf2ce9-ad3f-4eb8-bd1d-12e703475283",
   "metadata": {},
   "source": [
    "## In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ca45d-e502-4037-918f-0a5123107021",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, we can handle missing data by implementing one of the below methods:\n",
    "\n",
    "__Multiple imputation (MI):__ In this method, missing data are imputed multiple times to create several complete datasets. The consequence of using this method is that it can be computationally intensive and may require assumptions about the distribution of the missing data.\n",
    "\n",
    "__Last observation carried forward (LOCF):__ In this method, the last observed value is carried forward to replace the missing value. The consequence of using this method is that it assumes that the missing value is the same as the last observed value, which may not be accurate if the outcome variable is changing over time.\n",
    "\n",
    "The consequences of using different methods to handle missing data can be significant, and the choice of method should be based on the nature and extent of the missing data, as well as the assumptions underlying the method. In general, it is recommended to use multiple imputation or other methods that account for the uncertainty associated with missing data whenever possible, to avoid bias and improve the accuracy of the estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0507c-8d1d-44a3-b5f9-fad7eeadbcec",
   "metadata": {},
   "source": [
    "## What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281735b2-2a55-427a-8642-1a941436a4cf",
   "metadata": {},
   "source": [
    "Post-hoc tests are used in ANOVA to compare means between different groups after a significant main effect has been detected. These tests help to identify which groups are significantly different from one another. Here are some common post-hoc tests used after ANOVA, along with situations where they might be appropriate:\n",
    "\n",
    "* Tukey's HSD (Honestly Significant Difference) Test: This test is used when the number of groups is equal and the sample sizes are equal or nearly equal. Tukey's HSD test controls the family-wise error rate, meaning it is less likely to produce false positive results (Type I error).\n",
    "\n",
    "* Bonferroni Correction: This test is used when the number of pairwise comparisons is large. It is more conservative than other post-hoc tests because it adjusts the significance level to account for multiple comparisons.\n",
    "\n",
    "* Scheffe's Test: This test is used when the number of groups is unequal, the sample sizes are unequal, and the variances are unequal. Scheffe's test is more conservative than other post-hoc tests, meaning it is less likely to produce false positive results (Type I error).\n",
    "\n",
    "* Games-Howell Test: This test is used when the number of groups is unequal and the variances are unequal. It is a more powerful test than Scheffe's test, but it is less powerful than other post-hoc tests when the variances are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3d250-a184-4081-b57c-de65864958d5",
   "metadata": {},
   "source": [
    "## A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daec9524-1bb9-4350-9b7f-d6856267b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the Null Hypothesis: there is significant differences between the mean weight loss of at least one of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "\n",
    "# Generate random weight loss data for each diet\n",
    "np.random.seed(6)\n",
    "diet_a = np.random.normal(10,8,20)\n",
    "diet_b = np.random.normal(12, 9, 15)\n",
    "diet_c = np.random.normal(8, 5, 15)\n",
    "alpha = 0.05 #(default)\n",
    "\n",
    "# Conduct one-way ANOVA on the weight loss data\n",
    "f_stat, p_val = stat.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "# decision making and printing the results\n",
    "if(p_val <alpha):\n",
    "    print(\"Reject the Null Hypothesis: there is significant differences between the mean weight loss of at least one of the three diets.\")    \n",
    "else:\n",
    "    print(\"We Fail to Reject the NULL hypothesis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6bc28-f8ff-44db-b9b9-52946aed92fb",
   "metadata": {},
   "source": [
    "## A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6a75896-ad21-4f03-a5bc-c67359a4975d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(Program)</th>\n",
       "      <td>0.186339</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.994670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(ExperienceLevel)</th>\n",
       "      <td>18.419672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.056791</td>\n",
       "      <td>0.314198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Program):C(ExperienceLevel)</th>\n",
       "      <td>22.164852</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.635832</td>\n",
       "      <td>0.538182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>418.315476</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sum_sq    df         F    PR(>F)\n",
       "C(Program)                       0.186339   2.0  0.005345  0.994670\n",
       "C(ExperienceLevel)              18.419672   1.0  1.056791  0.314198\n",
       "C(Program):C(ExperienceLevel)   22.164852   2.0  0.635832  0.538182\n",
       "Residual                       418.315476  24.0       NaN       NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "prog = np.repeat(('A','B','C'), 10)\n",
    "expLev = np.repeat(('novice', 'experienced'),15)\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(prog)\n",
    "np.random.shuffle(expLev)\n",
    "time = np.random.randint(10, 25, 30)\n",
    "\n",
    "df = pd.DataFrame({'Program': prog, 'ExperienceLevel': expLev, 'Time': time})\n",
    "\n",
    "# Performing two-way ANOVA\n",
    "model = ols('Time ~ C(Program)+ C(ExperienceLevel) + C(Program):C(ExperienceLevel)', data = df).fit()\n",
    "\n",
    "sm.stats.anova_lm(model, typ =2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e32f6e-0ed9-4792-884a-254e554a3e4e",
   "metadata": {},
   "source": [
    "we can see that the p-values for all the main effects and interaction effect are greater than 0.05, which suggests that none of these effects are statistically significant at the 5% level. Therefore, we can conclude that there is no evidence of any significant differences in the average time it takes to complete the task across the different software programs or between novice and experienced employees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead2470-176c-484e-a538-c881133281aa",
   "metadata": {},
   "source": [
    "## An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65a1d2bd-f6eb-4407-9d2f-fd97fb774e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "'''\n",
    "h0 = mean1 = mean2\n",
    "h1 = mean1 != mean2\n",
    "'''\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(2)\n",
    "score = np.random.randint(50,100, 100)\n",
    "group = np.repeat(('Control', 'Experimental'), 50)\n",
    "np.random.shuffle(group)\n",
    "\n",
    "# make dataframe\n",
    "df = pd.DataFrame({'Score': score, 'Group': group})\n",
    "\n",
    "# seperate the group score\n",
    "grp1 = df[df['Group']== 'Control']['Score']\n",
    "grp2 = df[df['Group']== 'Experimental']['Score']\n",
    "\n",
    "# conduct two sample t-test\n",
    "stat , p_val = stat.ttest_ind(grp1, grp2 )\n",
    "\n",
    "alpha = 0.05\n",
    "if p_val < alpha:\n",
    "    print('reject the null hypothesis')\n",
    "else:\n",
    "    print('fail to reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138f0dc-1e35-4a92-9dc5-816d16ff0c63",
   "metadata": {},
   "source": [
    "#### Since the difference is significant, performing post-hoc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c37231c9-c280-4de3-9bb1-9214c5b76d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05     \n",
      "============================================================\n",
      " group1    group2    meandiff p-adj   lower    upper  reject\n",
      "------------------------------------------------------------\n",
      "Control Experimental    -7.02 0.0132 -12.5401 -1.4999   True\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tukey=pairwise_tukeyhsd( df['Score'],df['Group'])\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f74f2b-d3c9-4357-b01b-e0eb572f1155",
   "metadata": {},
   "source": [
    "This means that the mean test score for the Experimental group is 7.02 points lower than that of the Control group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0890b-8a07-472f-a1fd-4f8dfd416de4",
   "metadata": {},
   "source": [
    "## A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each storeon those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4764e558-e7af-4c29-a8d3-32406e465b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>ddof2</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>ng2</th>\n",
       "      <th>eps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>day</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>1.961647</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.06514</td>\n",
       "      <td>0.059421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source  ddof1  ddof2         F     p-unc      ng2       eps\n",
       "0    day     29     58  1.961647  0.014657  0.06514  0.059421"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pingouin as pg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.stats.multicomp as mp\n",
    "\n",
    "# generate random data\n",
    "np.random.seed(4)\n",
    "store = np.repeat(('A', 'B', 'C'), 30)\n",
    "sales = np.concatenate([np.random.randint(300, 450, 30), np.random.randint(200, 210, 30) , np.random.randint(250, 350, 30)])\n",
    "df = pd.DataFrame({'store': store, 'sales': sales, 'day': list(range(1,31))*3})\n",
    "\n",
    "# conducting repeated measure anova\n",
    "pg.rm_anova(dv = 'sales', within = 'day', subject='store', data= df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c95ec-306c-4968-a2b6-295ae18bc722",
   "metadata": {},
   "source": [
    "p-value of 0.014657, which is less than the alpha level of 0.05 indicating that there is a significant difference between at least two of the conditions.\n",
    " \n",
    "   \n",
    "One common post-hoc test is the Tukey HSD test, which can be performed using the pairwise_tukeyhsd function from the statsmodels library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "69dd65d1-373f-46db-a9d1-07ed51073b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      "group1 group2  meandiff p-adj   lower     upper   reject\n",
      "--------------------------------------------------------\n",
      "     A      B -177.9333   0.0 -195.6434 -160.2233   True\n",
      "     A      C  -84.9333   0.0 -102.6434  -67.2233   True\n",
      "     B      C      93.0   0.0     75.29    110.71   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# perform Tukey HSD post-hoc test\n",
    "tus = mp.pairwise_tukeyhsd(df['sales'], df['store'] )\n",
    "print(tus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e2ee4-bce4-4ea3-a0e2-d77194d3d473",
   "metadata": {},
   "source": [
    "The p-values for all three pairwise comparisons are less than the alpha level of 0.05, indicating that there are significant differences between the means of at least two of the groups. We can see that group A has significantly lower mean sales than groups B and C, while there is a significant difference in mean sales between groups B and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7a094-b347-41ea-ad48-1343d87921fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
